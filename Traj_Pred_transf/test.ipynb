{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset format: ori_data, neighbor_matrices, _, num_observed_vehicles\n",
    "from feeder_ngsim import NgsimFeeder\n",
    "from models import SpatialTransformerRNN\n",
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def preprocess_data(data, rescale_xy, neighbor_matrices, observed_last):\n",
    "    # data: (N, C, T, V)\n",
    "    # vehicle_ids = data[:, 1:2, :, :] # (N, 1, T, V)\n",
    "    feature_id = [3, 4, 5, 6] # local x, local y, lane_id, mark\n",
    "    ori_data = data[:, feature_id].detach()\n",
    "    data = ori_data.detach().clone()\n",
    "\n",
    "    new_mask = (data[:, :2, 1:] != 0) * (data[:, :2, :-1] != 0) # (N, 2, T-1, V)\n",
    "    new_mask[:, :2, observed_last-1: observed_last+1] = 1 # the first is the target vehicle and the last observed and the first predicted frames' mask of this vehicle must be 1.\n",
    "    # It is easier to predict the velocity of an object than predicting its location.\n",
    "    # Calculate velocities p^{t+1} - p^{t} before feeding the data into the model.\n",
    "\n",
    "    #predict velocity\n",
    "    data[:, :2, 1:] = (data[:, :2, 1:] - data[:, :2, :-1]).float() * new_mask.float()\n",
    "    data[:, :2, 0] = 0\n",
    "\n",
    "    data = torch.cat([data[:, :2], ori_data[:, :2]], dim=1) # concat velocity and origin location.\n",
    "    # print(data[:,0,:,:].max())\n",
    "    # print(data[:,1,:,:].max())\n",
    "    # print(data[:,2,:,:].max())\n",
    "    # print(data[:,3,:,:].max())\n",
    "\n",
    "    data = data.float().to(device)\n",
    "    data[:, :4] = data[:, :4] / rescale_xy\n",
    "    ori_data = ori_data.float().to(device)\n",
    "    # vehicle_ids = vehicle_ids.long().to(args.device)\n",
    "\n",
    "    A = neighbor_matrices.to(device)\n",
    "\n",
    "\n",
    "    return data, ori_data, A"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def preprocess_data2(data, neighbor_matrices, observed_last):\n",
    "    # data: (N, C, T, V)\n",
    "    # vehicle_ids = data[:, 1:2, :, :] # (N, 1, T, V)\n",
    "    feature_id = [3, 4, 5, 6] # local x, local y, lane_id, mark\n",
    "    ori_data = data[:, feature_id].detach()\n",
    "    data = ori_data.detach().clone()\n",
    "\n",
    "\n",
    "    new_mask = (data[:, :2, 1:] != 0) * (data[:, :2, :-1] != 0) # (N, 2, T-1, V)\n",
    "    new_mask[:, :2, observed_last-1: observed_last+1] = 1 # the first is the target vehicle and the last observed and the first predicted frames' mask of this vehicle must be 1.\n",
    "    # It is easier to predict the velocity of an object than predicting its location.\n",
    "    # Calculate velocities p^{t+1} - p^{t} before feeding the data into the model.\n",
    "\n",
    "    #predict velocity\n",
    "    data[:, :2, 1:] = ((41/8)*(data[:, :2, 1:] - data[:, :2, :-1])).float() #* new_mask.float()\n",
    "    data[:, :2, 0] = 0\n",
    "\n",
    "    data = torch.cat([data[:, :2], ori_data[:, :2]], dim=1) # concat velocity and origin location.\n",
    "    # print(data[:,0,:,:].max())\n",
    "    # print(data[:,1,:,:].max())\n",
    "    # print(data[:,2,:,:].max())\n",
    "    # print(data[:,3,:,:].max())\n",
    "\n",
    "    data = data.float().to(device)\n",
    "    data[:, :4] = data[:, :4]\n",
    "    ori_data = ori_data.float().to(device)\n",
    "    # vehicle_ids = vehicle_ids.long().to(args.device)\n",
    "\n",
    "    A = neighbor_matrices.to(device)\n",
    "\n",
    "\n",
    "    return data, ori_data, A"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "max_x_velocity = 14.85\n",
    "max_x = 36.155\n",
    "max_y_velocity = 67.58\n",
    "max_y = 486.76\n",
    "th = 30\n",
    "ds = 2\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "rescale_xy = torch.ones((1, 4, 1, 1)).to(device)\n",
    "rescale_xy[:, 0] = max_x_velocity\n",
    "rescale_xy[:, 1] = max_y_velocity\n",
    "rescale_xy[:, 2] = max_x\n",
    "rescale_xy[:, 3] = max_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 41, 120])\n",
      "torch.Size([1, 4, 41, 120])\n"
     ]
    }
   ],
   "source": [
    "train_path = r'C:\\Users\\Hailong\\Projects\\ngsim_preprocessed_oldgit\\TrainSet.mat'\n",
    "\n",
    "dataset = NgsimFeeder(train_path, train_val_test='train')\n",
    "loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=1)\n",
    "input = torch.zeros([1,4,16,120])\n",
    "outlabel = torch.zeros([1,2,25,120])\n",
    "\n",
    "for iteration, (ori_data, neighbor_matrices, _, num_observed_vehicles) in enumerate(loader):\n",
    "    now_history_frames = th // ds + 1 # 30 // 2 + 1, 30: history frames, 2: down sampling steps\n",
    "    data, no_norm_loc_data, neighbor_matrices = preprocess_data(ori_data, rescale_xy, neighbor_matrices, observed_last=now_history_frames-1)\n",
    "    input_data = data[:, :, :now_history_frames, :]\n",
    "    # print(no_norm_loc_data[:,0,:,:].max())\n",
    "    # print(input_data.shape)\n",
    "    input = input_data\n",
    "    #extract label to compare prediction with\n",
    "    outputdata, _, _ = preprocess_data(ori_data, rescale_xy,neighbor_matrices, observed_last=now_history_frames-1)\n",
    "    output_label = outputdata[:, :2, now_history_frames:, :]\n",
    "    outlabel = output_label\n",
    "    #print(outlabel)\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#input_data = data[:, :, :now_history_frames, :]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "model = SpatialTransformerRNN(\n",
    "        in_size=4, out_size=2, seq2seq_type='gru',\n",
    "        n_layers=4,\n",
    "        interact_in_decoding=True,\n",
    "        spatial_interact=True\n",
    "    )\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    checkpoint_fpath = \"outputs/saved_models/STransformerRNN_1_4_1_gru_train_plus_val_0.0001_0.0_0.6_7_74036.pt\"\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.to(device)\n",
    "    A=torch.zeros([1,16,120,120],device=device)\n",
    "\n",
    "\n",
    "    predicted = model(input, pra_A=A, pra_pred_length=25, input_mask=None, teacher_forcing_ratio=0.0,\n",
    "                    pra_teacher_location=None, is_train=False)\n",
    "    predicted = predicted[0]\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 3.0125e-04,  1.7742e-04, -2.9840e-05,  ..., -2.9840e-05,\n",
      "           -2.9840e-05, -2.9840e-05],\n",
      "          [ 1.8373e-04,  1.0122e-04, -5.3657e-06,  ..., -5.3657e-06,\n",
      "           -5.3657e-06, -5.3657e-06],\n",
      "          [ 1.6451e-04,  7.3232e-05, -7.1679e-06,  ..., -7.1679e-06,\n",
      "           -7.1679e-06, -7.1679e-06],\n",
      "          ...,\n",
      "          [ 2.0297e-05,  1.8536e-05,  4.7565e-06,  ...,  4.7565e-06,\n",
      "            4.7565e-06,  4.7565e-06],\n",
      "          [ 1.8899e-05,  1.7922e-05,  5.4828e-06,  ...,  5.4828e-06,\n",
      "            5.4828e-06,  5.4828e-06],\n",
      "          [ 1.7595e-05,  1.7323e-05,  6.1848e-06,  ...,  6.1848e-06,\n",
      "            6.1848e-06,  6.1848e-06]],\n",
      "\n",
      "         [[ 9.8128e-02,  5.8720e-02, -7.0543e-03,  ..., -7.0543e-03,\n",
      "           -7.0543e-03, -7.0543e-03],\n",
      "          [ 6.0752e-02,  3.4576e-02,  7.0228e-04,  ...,  7.0228e-04,\n",
      "            7.0228e-04,  7.0228e-04],\n",
      "          [ 5.4679e-02,  2.5714e-02,  2.2364e-04,  ...,  2.2364e-04,\n",
      "            2.2364e-04,  2.2364e-04],\n",
      "          ...,\n",
      "          [ 8.7785e-03,  8.2478e-03,  3.8998e-03,  ...,  3.8998e-03,\n",
      "            3.8998e-03,  3.8998e-03],\n",
      "          [ 8.3356e-03,  8.0519e-03,  4.1293e-03,  ...,  4.1293e-03,\n",
      "            4.1293e-03,  4.1293e-03],\n",
      "          [ 7.9225e-03,  7.8611e-03,  4.3512e-03,  ...,  4.3512e-03,\n",
      "            4.3512e-03,  4.3512e-03]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted = predicted#*rescale_xy[:,:2,:,:]\n",
    "\n",
    "#print((predicted*rescale_xy[:,:2,:,:]).max())\n",
    "print(predicted)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0161, 0.0096, 0.0111, 0.0123, 0.0123, 0.0122, 0.0139, 0.0145, 0.0141,\n",
      "         0.0150, 0.0146, 0.0166, 0.0183, 0.0195, 0.0200, 0.0217, 0.0225, 0.0220,\n",
      "         0.0211, 0.0222, 0.0237, 0.0254, 0.0264, 0.0266, 0.0272]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x2y2 = torch.sum(torch.abs(predicted - outlabel) ** 2, dim=1) # x^2+y^2, (N, C, T, V)->(N, T, V)=(N, 25, 255)\n",
    "overall_sum_time = x2y2.sum(dim=-1) # (N, T, V) -> (N, T)=(N, 25)\n",
    "print(overall_sum_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[14.8500]],\n\n         [[67.5800]]]], device='cuda:0')"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#understand rescaling and the units\n",
    "#write the function\n",
    "\n",
    "rescale_xy[:,:2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def traj_pred(A, past_traj, model):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def preprocess_data(data, rescale_xy, neighbor_matrices, observed_last):\n",
    "    # data: (N, C, T, V)\n",
    "    # vehicle_ids = data[:, 1:2, :, :] # (N, 1, T, V)\n",
    "    feature_id = [3, 4, 5, 6] # local x, local y, lane_id, mark\n",
    "    ori_data = data[:, feature_id].detach()\n",
    "\n",
    "    # convert to meters\n",
    "    # ori_data = 0.3048*ori_data\n",
    "\n",
    "    data = ori_data.detach().clone()\n",
    "\n",
    "\n",
    "    new_mask = (data[:, :2, 1:] != 0) * (data[:, :2, :-1] != 0) # (N, 2, T-1, V)\n",
    "    new_mask[:, :2, observed_last-1: observed_last+1, 0] = 1 # the first is the target vehicle and the last observed and the first predicted frames' mask of this vehicle must be 1.\n",
    "    # It is easier to predict the velocity of an object than predicting its location.\n",
    "    # Calculate velocities p^{t+1} - p^{t} before feeding the data into the model.\n",
    "\n",
    "    data[:, :2, 1:] = (data[:, :2, 1:] - data[:, :2, :-1]).float() * new_mask.float()\n",
    "\n",
    "    data[:, :2, 0] = 0\n",
    "\n",
    "    data = torch.cat([data[:, :2], ori_data[:, :2]], dim=1) # concat velocity and origin location.\n",
    "\n",
    "\n",
    "\n",
    "    data = data.float().to(device)\n",
    "    data[:, :4] = data[:, :4] / rescale_xy\n",
    "    ori_data = ori_data.float().to(device)\n",
    "    # vehicle_ids = vehicle_ids.long().to(args.device)\n",
    "\n",
    "    A = neighbor_matrices.to(device)\n",
    "\n",
    "\n",
    "    return data, ori_data, A"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def preprocess_data2(data, neighbor_matrices, observed_last):\n",
    "    # data: (N, C, T, V)\n",
    "    # vehicle_ids = data[:, 1:2, :, :] # (N, 1, T, V)\n",
    "    feature_id = [3, 4, 5, 6] # local x, local y, lane_id, mark\n",
    "    ori_data = data[:, feature_id].detach()\n",
    "\n",
    "    # convert to meters\n",
    "    # ori_data = 0.3048*ori_data\n",
    "\n",
    "    data = ori_data.detach().clone()\n",
    "\n",
    "\n",
    "    new_mask = (data[:, :2, 1:] != 0) * (data[:, :2, :-1] != 0) # (N, 2, T-1, V)\n",
    "    new_mask[:, :2, observed_last-1: observed_last+1, 0] = 1 # the first is the target vehicle and the last observed and the first predicted frames' mask of this vehicle must be 1.\n",
    "    # It is easier to predict the velocity of an object than predicting its location.\n",
    "    # Calculate velocities p^{t+1} - p^{t} before feeding the data into the model.\n",
    "\n",
    "    data[:, :2, 1:] = (data[:, :2, 1:] - data[:, :2, :-1]).float() * new_mask.float()\n",
    "\n",
    "    data[:, :2, 0] = 0\n",
    "\n",
    "    data = torch.cat([data[:, :2], ori_data[:, :2]], dim=1) # concat velocity and origin location.\n",
    "\n",
    "\n",
    "\n",
    "    data = data.float().to(device)\n",
    "\n",
    "    ori_data = ori_data.float().to(device)\n",
    "    # vehicle_ids = vehicle_ids.long().to(args.device)\n",
    "\n",
    "    A = neighbor_matrices.to(device)\n",
    "\n",
    "\n",
    "    return data, ori_data, A"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "max_x_velocity = 14.85\n",
    "max_x = 36.155\n",
    "max_y_velocity = 67.58\n",
    "max_y = 486.76\n",
    "th = 30\n",
    "ds = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "rescale_xy = torch.ones((1, 4, 1, 1)).to(device)\n",
    "rescale_xy[:, 0] = max_x_velocity\n",
    "rescale_xy[:, 1] = max_y_velocity\n",
    "rescale_xy[:, 2] = max_x\n",
    "rescale_xy[:, 3] = max_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 1, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[1, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 1, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[1, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 1, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1, 1, 0,  ..., 0, 0, 0],\n",
      "          [1, 1, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[1, 1, 0,  ..., 0, 0, 0],\n",
      "          [1, 1, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[1, 1, 0,  ..., 0, 0, 0],\n",
      "          [1, 1, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]]], device='cuda:0', dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "train_path = r'C:\\Users\\Hailong\\Projects\\ngsim_preprocessed_oldgit\\TrainSet.mat'\n",
    "\n",
    "dataset = NgsimFeeder(train_path, train_val_test='train')\n",
    "loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=1)\n",
    "input = torch.zeros([1,4,16,120])\n",
    "outlabel = torch.zeros([1,2,25,120])\n",
    "A=torch.zeros([1,2,120,120])\n",
    "\n",
    "for iteration, (ori_data, neighbor_matrices, _, num_observed_vehicles) in enumerate(loader):\n",
    "    now_history_frames = th // ds + 1 # 30 // 2 + 1, 30: history frames, 2: down sampling steps\n",
    "    data, no_norm_loc_data, neighbor_matrices = preprocess_data(ori_data, rescale_xy, neighbor_matrices, observed_last=now_history_frames-1)\n",
    "    input_data = data[:, :, :now_history_frames, :]\n",
    "    # print(no_norm_loc_data[:,0,:,:].max())\n",
    "    # print(input_data.shape)\n",
    "    input = input_data\n",
    "    #extract label to compare prediction with\n",
    "    outputdata, _, _ = preprocess_data2(ori_data, neighbor_matrices=neighbor_matrices, observed_last=now_history_frames-1)\n",
    "    output_label = outputdata[:, 2:4, now_history_frames:, :]\n",
    "    outlabel = output_label\n",
    "    A=neighbor_matrices\n",
    "\n",
    "\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "model = SpatialTransformerRNN(\n",
    "        in_size=4, out_size=2, seq2seq_type='gru',\n",
    "        n_layers=4,\n",
    "        interact_in_decoding=True,\n",
    "        spatial_interact=True\n",
    "    )\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    checkpoint_fpath = \"outputs/saved_models/STransformerRNN_1_4_1_gru_train_plus_val_0.0001_0.0_0.6_3_111054.pt\"\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    predicted = model(input, pra_A=A, pra_pred_length=25, input_mask=None, teacher_forcing_ratio=0.0,\n",
    "                    pra_teacher_location=None, is_train=False)\n",
    "    predicted = predicted[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 25, 120])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted = predicted*rescale_xy[:,2:4,:,:]\n",
    "\n",
    "#print((predicted*rescale_xy[:,:2,:,:]).max())\n",
    "print(predicted.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[39207.4141, 17792.8145, 16384.8418, 15177.2773, 13957.9160, 12360.0137,\n",
      "         10430.7480,  8344.1387,  6276.8760,  4357.1230,  2702.5264,  1412.9247,\n",
      "           573.5718,   269.0222,   604.4550,  1690.0940,  3639.6899,  6574.7915,\n",
      "         10633.3086, 15953.3359, 22669.8125, 30956.1699, 41004.1406, 53006.8398,\n",
      "         67174.4219]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x2y2 = torch.sum(torch.abs(predicted - outlabel) ** 2, dim=1) # x^2+y^2, (N, C, T, V)->(N, T, V)=(N, 25, 255)\n",
    "overall_sum_time = x2y2.sum(dim=-1) # (N, T, V) -> (N, T)=(N, 25)\n",
    "print(overall_sum_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(14.4039, device='cuda:0')"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted-outlabel)[:,1,18].max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
