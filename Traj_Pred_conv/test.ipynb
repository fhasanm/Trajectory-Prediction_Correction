{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from model import highwayNet\n",
    "from utils import ngsimDataset, maskedNLL, maskedMSETest, maskedNLLTest\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#device = torch.device('cpu')\n",
    "args = {}\n",
    "args['use_cuda'] = True\n",
    "args['encoder_size'] = 64\n",
    "args['decoder_size'] = 128\n",
    "args['in_length'] = 16\n",
    "args['out_length'] = 25\n",
    "args['grid_size'] = (13, 3)\n",
    "args['soc_conv_depth'] = 64\n",
    "args['conv_3x1_depth'] = 16\n",
    "args['dyn_embedding_size'] = 32\n",
    "args['input_embedding_size'] = 32\n",
    "args['num_lat_classes'] = 3\n",
    "args['num_lon_classes'] = 2\n",
    "args['use_maneuvers'] = False\n",
    "args['train_flag'] = False\n",
    "\n",
    "net = highwayNet(args)\n",
    "net.load_state_dict(torch.load('trained_models/cslstm_m_0.pt'))\n",
    "net = net.to(device)\n",
    "tsSet = ngsimDataset(r'C:\\Users\\Hailong\\Projects\\ngsim_preprocessed_oldgit\\TestSet.mat')\n",
    "tsDataloader = DataLoader(tsSet, batch_size=128, shuffle=True, num_workers=8, collate_fn=tsSet.collate_fn)\n",
    "\n",
    "pred = torch.zeros(25,1,2)\n",
    "gt = torch.zeros(25,1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0050048828125\n"
     ]
    }
   ],
   "source": [
    "st_time = time.time()\n",
    "for i, data in enumerate(tsDataloader):\n",
    "\n",
    "    hist, nbrs, masks, lat_enc, lon_enc, fut_label, op_mask  = data\n",
    "\n",
    "    masks = torch.zeros([hist.shape[1], 3, 13, 64], device=\"cpu\").bool()\n",
    "    # Initialize Variables\n",
    "\n",
    "    if args['use_cuda']:\n",
    "        hist = hist.cuda()\n",
    "        nbrs = nbrs.cuda()\n",
    "        masks = masks.cuda()\n",
    "        lat_enc = lat_enc.cuda()\n",
    "        lon_enc = lon_enc.cuda()\n",
    "        fut_label = fut_label.cuda()\n",
    "        op_mask = op_mask.cuda()\n",
    "    # hist.to(device)\n",
    "    # nbrs.to(device)\n",
    "    # # mask = mask.to(device)\n",
    "    # #op_mask = torch.ones(25,1,2)\n",
    "    # fut_label.to(device)\n",
    "\n",
    "    #masks = torch.ones([hist.shape[1], 3, 13, 64], device=\"cuda\").bool()\n",
    "\n",
    "    # Forward pass\n",
    "    st_time = time.time()\n",
    "    fut_pred = net(hist, nbrs, masks)\n",
    "    time_taken = time.time() - st_time\n",
    "    print(time_taken)\n",
    "    pred = fut_pred[:,2,:2]\n",
    "    gt = fut_label[:,2,:]\n",
    "\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.1700e-01,  4.8750e+00],\n        [ 3.0100e-01,  1.0189e+01],\n        [ 4.0800e-01,  1.6096e+01],\n        [ 3.8100e-01,  2.2442e+01],\n        [ 3.7900e-01,  2.8789e+01],\n        [ 1.7900e-01,  3.4965e+01],\n        [-1.5900e-01,  4.1161e+01],\n        [-2.7400e-01,  4.7886e+01],\n        [-3.2000e-01,  5.5112e+01],\n        [-4.0300e-01,  6.2399e+01],\n        [-4.8700e-01,  6.9663e+01],\n        [-5.7100e-01,  7.6930e+01],\n        [-6.5400e-01,  8.4196e+01],\n        [-7.3800e-01,  9.1525e+01],\n        [-8.3500e-01,  9.8310e+01],\n        [-7.4600e-01,  1.0483e+02],\n        [-6.5600e-01,  1.1201e+02],\n        [-5.6800e-01,  1.1928e+02],\n        [-4.7900e-01,  1.2654e+02],\n        [-3.9000e-01,  1.3381e+02],\n        [-3.0000e-01,  1.4106e+02],\n        [-2.4700e-01,  1.4836e+02],\n        [-1.7700e-01,  1.5603e+02],\n        [-3.7998e-02,  1.6403e+02],\n        [ 1.4000e-01,  1.7204e+02]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[(tensor(-0.2460, grad_fn=<SubBackward0>),\n  tensor(0.0613, grad_fn=<SubBackward0>)),\n (tensor(-0.5024, grad_fn=<SubBackward0>),\n  tensor(0.1434, grad_fn=<SubBackward0>)),\n (tensor(-0.3526, grad_fn=<SubBackward0>),\n  tensor(0.2280, grad_fn=<SubBackward0>)),\n (tensor(-0.2097, grad_fn=<SubBackward0>),\n  tensor(0.6160, grad_fn=<SubBackward0>)),\n (tensor(-0.0707, grad_fn=<SubBackward0>),\n  tensor(0.7322, grad_fn=<SubBackward0>)),\n (tensor(0.0003, grad_fn=<SubBackward0>),\n  tensor(0.5756, grad_fn=<SubBackward0>)),\n (tensor(-0.3072, grad_fn=<SubBackward0>),\n  tensor(0.9235, grad_fn=<SubBackward0>)),\n (tensor(-0.1715, grad_fn=<SubBackward0>),\n  tensor(1.1191, grad_fn=<SubBackward0>)),\n (tensor(0.5505, grad_fn=<SubBackward0>),\n  tensor(1.1087, grad_fn=<SubBackward0>)),\n (tensor(0.7802, grad_fn=<SubBackward0>),\n  tensor(0.5268, grad_fn=<SubBackward0>)),\n (tensor(0.7439, grad_fn=<SubBackward0>),\n  tensor(-0.0278, grad_fn=<SubBackward0>)),\n (tensor(0.7937, grad_fn=<SubBackward0>),\n  tensor(-0.2295, grad_fn=<SubBackward0>)),\n (tensor(1.1196, grad_fn=<SubBackward0>),\n  tensor(-0.2015, grad_fn=<SubBackward0>)),\n (tensor(1.3118, grad_fn=<SubBackward0>),\n  tensor(0.9108, grad_fn=<SubBackward0>)),\n (tensor(1.6751, grad_fn=<SubBackward0>),\n  tensor(1.6883, grad_fn=<SubBackward0>)),\n (tensor(1.7497, grad_fn=<SubBackward0>),\n  tensor(1.7966, grad_fn=<SubBackward0>)),\n (tensor(1.6767, grad_fn=<SubBackward0>),\n  tensor(2.9537, grad_fn=<SubBackward0>)),\n (tensor(1.6277, grad_fn=<SubBackward0>),\n  tensor(4.5565, grad_fn=<SubBackward0>)),\n (tensor(1.5432, grad_fn=<SubBackward0>),\n  tensor(6.2393, grad_fn=<SubBackward0>)),\n (tensor(1.4593, grad_fn=<SubBackward0>),\n  tensor(7.6514, grad_fn=<SubBackward0>)),\n (tensor(1.3888, grad_fn=<SubBackward0>),\n  tensor(8.8757, grad_fn=<SubBackward0>)),\n (tensor(1.3178, grad_fn=<SubBackward0>),\n  tensor(9.6407, grad_fn=<SubBackward0>)),\n (tensor(1.2286, grad_fn=<SubBackward0>),\n  tensor(9.7733, grad_fn=<SubBackward0>)),\n (tensor(1.1140, grad_fn=<SubBackward0>),\n  tensor(10.8517, grad_fn=<SubBackward0>))]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "[(gt[i,0] - pred[i,0],gt[i,1] - pred[i,1]) for i in range(0,pred.shape[0]-1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "[(tensor(0.0086, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(0.4272, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(-0.0103, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(1.1993, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(-0.0167, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(0.4899, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(-0.0227, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(0.6104, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.0048, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(1.3968, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.0004, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(2.2555, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(-0.0085, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(2.2133, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(-0.0310, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(2.2780, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(-0.0455, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(3.5011, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.0270, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(5.3314, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.0989, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(7.3014, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.1653, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(9.0621, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.3800, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(10.8701, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(-0.0401, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(10.7349, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.0156, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(10.7412, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.1168, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(10.2063, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.2406, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(8.7701, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.4019, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(6.3800, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.5549, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(4.4574, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.6678, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(5.1991, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.7297, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(6.3161, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.7821, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(7.7848, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.8153, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(9.6148, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.8612, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(11.8095, device='cuda:0', grad_fn=<SubBackward0>))]"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(gt[i,0] - pred[i,0],gt[i,1] - pred[i,1]) for i in range(0,pred.shape[0]-1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "[(tensor(0.1543, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-0.1117, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.4375, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-0.5461, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.9964, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-0.7245, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(1.5082, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-0.8277, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(2.0265, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-0.5812, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(2.4533, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-0.4450, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(2.6490, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-0.5330, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(2.6016, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-0.5945, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(2.4571, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-0.7837, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(2.5067, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-0.8832, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(2.5276, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-1.3821, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(2.4164, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-2.4678, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(2.3782, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-3.7090, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(2.3517, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-4.7948, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(2.3483, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-5.9137, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(2.2989, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-7.4703, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(1.9291, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-9.5936, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(1.4803, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-11.5704, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(1.1227, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-12.8931, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.7637, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-14.8596, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.4039, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-16.8374, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.3508, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-18.2262, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.5523, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-19.8916, device='cuda:0', grad_fn=<SubBackward0>)),\n (tensor(0.6503, device='cuda:0', grad_fn=<SubBackward0>),\n  tensor(-22.0313, device='cuda:0', grad_fn=<SubBackward0>))]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(gt[i,0] - pred[i,0],gt[i,1] - pred[i,1]) for i in range(0,pred.shape[0]-1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#b,c,t,n\n",
    "model = highwayNet(args)\n",
    "tracks = torch.randn([2,16,120])\n",
    "\n",
    "#assumes tracks is c,t,n, c=4, first two in c is velocity\n",
    "def traj_pred(model, tracks):\n",
    "    #for each vehicle\n",
    "\n",
    "    tracks = tracks.reshape(1, tracks.shape[0], tracks.shape[1], tracks.shape[2]) # c t n -> b c t n\n",
    "    predictions = torch.zeros(2, 25, tracks.shape[3])\n",
    "    for i in range(tracks.shape[3]):\n",
    "        # proj = tracks[:,:,-1,i].repeat(tracks.shape[3], 1)\n",
    "        # assert proj.shape == tracks.shape, \"proj and tracks mismatch\"\n",
    "        transform = tracks[:,:,-1,i]\n",
    "        transformed_tracks = tracks - transform # transforms the coordinate frame to target vehicle at t=0\n",
    "\n",
    "        nbrs = transformed_tracks.reshape(transformed_tracks.shape[1],transformed_tracks.shape[2], transformed_tracks.shape[3])\n",
    "        nbrs = nbrs.permute(1,2,0) #c,t,n -> t,n,c\n",
    "        assert nbrs.shape == (tracks.shape[2], tracks.shape[3], tracks.shape[1]), \"nbrs shape error\"\n",
    "\n",
    "        hist = transformed_tracks[:,:,:,i].reshape(transformed_tracks.shape[0],transformed_tracks.shape[1], transformed_tracks.shape[2])\n",
    "        hist = hist.permute(2,0,1) #b,c,t -> t, b, c\n",
    "        assert hist.shape == (tracks.shape[2], tracks.shape[0], tracks.shape[1]), \"hist shape error\"\n",
    "\n",
    "        masks = torch.zeros([hist.shape[1], 3, 13, 64], device=\"cuda\" if torch.cuda.is_available() else 'cpu').bool()\n",
    "        fut = model(hist, nbrs, masks)\n",
    "        fut = fut_pred[:,:,:2]\n",
    "\n",
    "        fut = fut.reshape(1,fut.shape[0], fut.shape[1], fut.shape[2]) #t b c -> 1 t b c\n",
    "        fut = fut.permute(2,3,1,0) #n t b c -> b c t n\n",
    "        fut = fut + transform\n",
    "        fut = fut.reshape(fut.shape[1], fut.shape[2], fut.shape[3])\n",
    "\n",
    "        predictions[:,:,i] = fut\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "traj_pred(model, tracks)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
